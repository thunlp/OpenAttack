FRENCH:

# This deletes the last line of each file ($ is last line, d is delete)
for l in en fr; do for f in /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/*.$l; do if [[ "$f" != *"test"* ]]; then sed -i "$ d" $f; fi;  done; done
for l in en fr; do for f in /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done
python preprocess.py -train_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.en.atok -train_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.fr.atok -valid_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.en.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.fr.atok -save_data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr.atok
python preprocess.py -train_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.en.atok -train_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.fr.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.en.atok -valid_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.fr.atok -save_data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-fren.atok

python train.py -data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr.atok -save_model trained_models/english_french_model -gpuid 0
python train.py -data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-fren.atok -save_model trained_models/french_english_model -gpuid 1

German:

for l in en de; do for f in /home/marcotcr/phd/datasets/stanford_translation_data/en-de/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done
dd if=/dev/urandom of=/tmp/myrand count=100024
shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train.en.atok > /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.en.atok
shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train.de.atok > /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.de.atok

python preprocess.py -train_src /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.en.atok -train_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.de.atok -valid_src /home/marcotcr/phd/datasets/stanford_translation_data/en-de/test.en.atok -valid_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-de/test.de.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_ende.atok
python preprocess.py -train_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.en.atok -train_src /home/marcotcr/phd/datasets/stanford_translation_data/en-de/train_reduced.de.atok -valid_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-de/test.en.atok -valid_src /home/marcotcr/phd/datasets/stanford_translation_data/en-de/test.de.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_deen.atok

python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_ende.atok -save_model trained_models/english_german_model -gpuid 0
python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_deen.atok -save_model trained_models/german_english_model -gpuid 1

# Old dataset, before stanford:
# concat stuff
# for l in en de ; do cat /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/commoncrawl.de-en.$l.atok /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/europarl-v7.de-en.$l.atok /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/news-commentary-v10.de-en.$l.atok > /home/marcotcr/phd/OpenNMT-py/phd/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.$l.atok ; done
# dd if=/dev/urandom of=/tmp/myrand count=100024
# shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.en.atok > /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok
# shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.de.atok > /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok
# 
# python preprocess.py -train_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok -train_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok -valid_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.en.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.de.atok -save_data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-ende.atok
# python preprocess.py -train_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok -train_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.en.atok -valid_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.de.atok -save_data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-deen.atok
# 
# python train.py -data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-ende.atok -save_model trained_models/english_german_model -gpuid 0
# python train.py -data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-deen.atok -save_model trained_models/german_english_model -gpuid 1

Portuguese:
for l in en pt; do for f in /home/marcotcr/phd/datasets/translation/data_for_onmt/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done

python preprocess.py -train_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.en.atok -train_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.pt.atok -valid_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.en.atok -valid_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.pt.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_enpt.atok
python preprocess.py -train_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.en.atok -train_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.pt.atok -valid_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.en.atok -valid_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.pt.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_pten.atok

python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_enpt.atok -save_model trained_models/english_portuguese_model -gpuid 0
python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_pten.atok -save_model trained_models/portuguese_english_model -gpuid 1

Czech:
for l in en cs; do for f in /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done
dd if=/dev/urandom of=/tmp/myrand count=100024
shuf -n 4000000 --random-source /tmp/myrand /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train.en.atok > /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.en.atok
shuf -n 4000000 --random-source /tmp/myrand /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train.cs.atok > /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.cs.atok

python preprocess.py -train_src /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.en.atok -train_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.cs.atok -valid_src /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/test.en.atok -valid_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/test.cs.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_encs.atok
python preprocess.py -train_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.en.atok -train_src /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/train_reduced.cs.atok -valid_tgt /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/test.en.atok -valid_src /home/marcotcr/phd/datasets/stanford_translation_data/en-cs/test.cs.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_csen.atok

python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_encs.atok -save_model trained_models/english_czech_model -gpuid 0
python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_csen.atok -save_model trained_models/czech_english_model -gpuid 1

